[INFO ] fr.inria.main.evolution.AstorMain.setupLogging(AstorMain.java:272) - Log file at: /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/repairnator.astor.jkali.log
[INFO ] fr.inria.main.AbstractMain.determineSourceFolders(AbstractMain.java:982) - Source folders: [/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/debezium-core/src/main/java]
[INFO ] fr.inria.main.AbstractMain.determineSourceFolders(AbstractMain.java:1001) - Source Test folders: [/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/debezium-core/src/test/java]
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.calculateSuspicious(AstorCoreEngine.java:911) - Test retrieved from classes: 40
[INFO ] fr.inria.astor.core.manipulation.MutationSupporter.buildSpoonModel(MutationSupporter.java:236) - Creating model,  Code location from working folder: /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/debezium-core/src/main/java
[INFO ] fr.inria.astor.core.manipulation.MutationSupporter.buildModel(MutationSupporter.java:67) - building model: /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/debezium-core/src/main/java, compliance level: 8
[INFO ] fr.inria.astor.core.manipulation.MutationSupporter.buildModel(MutationSupporter.java:81) - Classpath (Dependencies) for building SpoonModel: [/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/connect-api/1.0.0/connect-api-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/kafka-clients/1.0.0/kafka-clients-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/lz4/lz4-java/1.4/lz4-java-1.4.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/connect-transforms/1.0.0/connect-transforms-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/fasterxml/jackson/core/jackson-core/2.9.1/jackson-core-2.9.1.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/junit/junit/4.12/junit-4.12.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/easytesting/fest-assert/1.4/fest-assert-1.4.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/easytesting/fest-util/1.1.6/fest-util-1.1.6.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/kafka_2.11/1.0.0/kafka_2.11-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.1/jackson-databind-2.9.1.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/scala-lang/scala-library/2.11.11/scala-library-2.11.11.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/curator/curator-test/2.11.0/curator-test-2.11.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/commons/commons-math/2.2/commons-math-2.2.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/jline/jline/0.9.94/jline-0.9.94.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/connect-json/1.0.0/connect-json-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/kafka-connect-avro-converter/4.0.0/kafka-connect-avro-converter-4.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/kafka-avro-serializer/4.0.0/kafka-avro-serializer-4.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/avro/avro/1.8.2/avro-1.8.2.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/thoughtworks/paranamer/paranamer/2.7/paranamer-2.7.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/tukaani/xz/1.5/xz-1.5.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/kafka-schema-registry-client/4.0.0/kafka-schema-registry-client-4.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/common-config/4.0.0/common-config-4.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/common-utils/4.0.0/common-utils-4.0.0.jar]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Connecting to zookeeper on localhost:33919
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Cluster ID = O9YPxTR0R_aNCaDWI4KOKw
[WARN ] kafka.utils.Logging$class.warn(Logging.scala:87) - No meta.properties file under dir /pfs/nobackup/home/d/dginelli/development/target/data/cluster/kafka/broker1/meta.properties
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Log directory '/pfs/nobackup/home/d/dginelli/development/target/data/cluster/kafka/broker1' not found, creating it.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading logs.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Logs loading complete in 14 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting log cleanup with a period of 300000 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting log flusher with a default period of 9223372036854775807 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting the log cleaner
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Awaiting socket connections on localhost:45573.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Started 1 acceptor threads
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Creating /controller (is it secure? false)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Starting up.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Startup complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Result of znode creation is: OK
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] 1 successfully elected as the controller
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting become controller state transition
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Incremented epoch to 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions being reassigned: Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions already reassigned: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resuming reassignment of partitions: Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Currently active brokers in the cluster: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Currently shutting brokers in the cluster: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Current list of topics in the cluster: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] List of topics to be deleted: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] List of topics ineligible for deletion: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Starting up.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Ready to serve as the new controller with epoch 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions undergoing preferred replica election: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions that completed preferred replica election: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resuming preferred replica election for partitions: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting preferred replica leader election for partitions 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Startup complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting the controller scheduler
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Creating /brokers/ids/1 (is it secure? false)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Result of znode creation is: OK
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,45573,ListenerName(PLAINTEXT),PLAINTEXT)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Newly added brokers: 1, deleted brokers: , all live brokers: 1
[WARN ] kafka.utils.Logging$class.warn(Logging.scala:87) - No meta.properties file under dir /pfs/nobackup/home/d/dginelli/development/target/data/cluster/kafka/broker1/meta.properties
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New broker startup callback for 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to localhost:45573 (id: 1 rack: null) for sending state change requests
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] started
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Topic creation {"version":1,"partitions":{"0":[1]}}
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topics: [Set(topicA)], deleted topics: [Set()], new partition replica assignment [Map(topicA-0 -> Vector(1))]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topic creation callback for topicA-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New partition creation callback for topicA-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions topicA-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=topicA,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions topicA-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions topicA-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=topicA,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Topic creation {"version":1,"partitions":{"0":[1]}}
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading producer state from offset 0 for partition topicA-0 with message format version 2
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Completed load of log topicA-0 with 1 log segments, log start offset 0 and log end offset 0 in 50 ms
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaApi-1] Auto creation of topic __consumer_offsets with 1 partitions and replication factor 1 is successful
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Created log for partition [topicA,0] in /pfs/nobackup/home/d/dginelli/development/target/data/cluster/kafka/broker1 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-0 -> Vector(1))]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topic creation callback for __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New partition creation callback for __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition topicA-0 broker=1] No checkpointed highwatermark is found for partition topicA-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Replica loaded for partition topicA-0 with initial high watermark 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition topicA-0 broker=1] topicA-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading producer state from offset 0 for partition __consumer_offsets-0 with message format version 2
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Completed load of log __consumer_offsets-0 with 1 log segments, log start offset 0 and log end offset 0 in 27 ms
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Created log for partition [__consumer_offsets,0] in /pfs/nobackup/home/d/dginelli/development/target/data/cluster/kafka/broker1 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 39 milliseconds.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group 0980f0be-e098-49a6-88c3-474e12b6189d with old generation 0 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: topicA-0. Cache now contains 0 entries.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group 0980f0be-e098-49a6-88c3-474e12b6189d generation 1 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group 0980f0be-e098-49a6-88c3-474e12b6189d for generation 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group 0980f0be-e098-49a6-88c3-474e12b6189d with old generation 1 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group 0980f0be-e098-49a6-88c3-474e12b6189d with generation 2 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] Starting controlled shutdown
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Shutting down broker 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] Controlled shutdown succeeded
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Kafka Request Handler on Broker 1], shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Kafka Request Handler on Broker 1], shut down completely
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaApi-1] Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction State Manager 1]: Shutdown complete
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaManager broker=1] Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaManager broker=1] Shut down completely
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutting down the log cleaner.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Stopped partition state machine
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Stopped replica state machine
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resigned
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] shut down completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/cluster/kafka/broker1/topicA-0/00000000000000000000.index
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/cluster/kafka/broker1/topicA-0/00000000000000000000.timeindex
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/cluster/kafka/broker1/__consumer_offsets-0/00000000000000000000.index
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/cluster/kafka/broker1/__consumer_offsets-0/00000000000000000000.timeindex
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Connecting to zookeeper on localhost:44385
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Cluster ID = wanpacYaQeGDaRm16QYwjA
[WARN ] kafka.utils.Logging$class.warn(Logging.scala:87) - No meta.properties file under dir /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/meta.properties
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Log directory '/pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1' not found, creating it.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading logs.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Logs loading complete in 11 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting log cleanup with a period of 300000 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting log flusher with a default period of 9223372036854775807 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting the log cleaner
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Awaiting socket connections on localhost:35761.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Started 1 acceptor threads
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Starting up.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Creating /controller (is it secure? false)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Startup complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Result of znode creation is: OK
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] 1 successfully elected as the controller
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting become controller state transition
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Starting up.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Startup complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Incremented epoch to 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Creating /brokers/ids/1 (is it secure? false)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Result of znode creation is: OK
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,35761,ListenerName(PLAINTEXT),PLAINTEXT)
[WARN ] kafka.utils.Logging$class.warn(Logging.scala:87) - No meta.properties file under dir /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/meta.properties
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions being reassigned: Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions already reassigned: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resuming reassignment of partitions: Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Currently active brokers in the cluster: Set(1)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Currently shutting brokers in the cluster: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Current list of topics in the cluster: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] List of topics to be deleted: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] List of topics ineligible for deletion: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Ready to serve as the new controller with epoch 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions undergoing preferred replica election: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions that completed preferred replica election: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resuming preferred replica election for partitions: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting preferred replica leader election for partitions 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to localhost:35761 (id: 1 rack: null) for sending state change requests
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting the controller scheduler
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] started
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Topic creation {"version":1,"partitions":{"0":[1]}}
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topics: [Set(schema-changes-topic)], deleted topics: [Set()], new partition replica assignment [Map(schema-changes-topic-0 -> Vector(1))]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topic creation callback for schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New partition creation callback for schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=schema-changes-topic,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=schema-changes-topic,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading producer state from offset 0 for partition schema-changes-topic-0 with message format version 2
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Completed load of log schema-changes-topic-0 with 1 log segments, log start offset 0 and log end offset 0 in 27 ms
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Created log for partition [schema-changes-topic,0] in /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition schema-changes-topic-0 broker=1] No checkpointed highwatermark is found for partition schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Replica loaded for partition schema-changes-topic-0 with initial high watermark 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition schema-changes-topic-0 broker=1] schema-changes-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Topic creation {"version":1,"partitions":{"0":[1]}}
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaApi-1] Auto creation of topic __consumer_offsets with 1 partitions and replication factor 1 is successful
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-0 -> Vector(1))]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topic creation callback for __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New partition creation callback for __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading producer state from offset 0 for partition __consumer_offsets-0 with message format version 2
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Completed load of log __consumer_offsets-0 with 1 log segments, log start offset 0 and log end offset 0 in 30 ms
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Created log for partition [__consumer_offsets,0] in /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 0 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 1 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 1 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 2 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: schema-changes-topic-0. Cache now contains 0 entries.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 2 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 3 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 3
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 3 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 4 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 4 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 5 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 5
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 5 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 6 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 6 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 7 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 7
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 7 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 8 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 8 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 9 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 9
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 9 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 10 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] Starting controlled shutdown
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Shutting down broker 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] Controlled shutdown succeeded
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Kafka Request Handler on Broker 1], shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Kafka Request Handler on Broker 1], shut down completely
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaApi-1] Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction State Manager 1]: Shutdown complete
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaManager broker=1] Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaManager broker=1] Shut down completely
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutting down the log cleaner.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Stopped partition state machine
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Stopped replica state machine
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resigned
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] shut down completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/__consumer_offsets-0/00000000000000000000.index
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/__consumer_offsets-0/00000000000000000000.timeindex
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/schema-changes-topic-0/00000000000000000000.index
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/schema-changes-topic-0/00000000000000000000.timeindex
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Connecting to zookeeper on localhost:44003
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Cluster ID = A7-QyCcXT3edUN_wFA10Eg
[WARN ] kafka.utils.Logging$class.warn(Logging.scala:87) - No meta.properties file under dir /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/meta.properties
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Log directory '/pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1' not found, creating it.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading logs.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Logs loading complete in 11 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting log cleanup with a period of 300000 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting log flusher with a default period of 9223372036854775807 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting the log cleaner
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Awaiting socket connections on localhost:37683.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Started 1 acceptor threads
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Starting up.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Creating /controller (is it secure? false)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Startup complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Result of znode creation is: OK
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] 1 successfully elected as the controller
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting become controller state transition
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Starting up.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Startup complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Incremented epoch to 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Creating /brokers/ids/1 (is it secure? false)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Result of znode creation is: OK
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,37683,ListenerName(PLAINTEXT),PLAINTEXT)
[WARN ] kafka.utils.Logging$class.warn(Logging.scala:87) - No meta.properties file under dir /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/meta.properties
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions being reassigned: Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions already reassigned: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resuming reassignment of partitions: Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Currently active brokers in the cluster: Set(1)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Currently shutting brokers in the cluster: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Current list of topics in the cluster: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] List of topics to be deleted: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] List of topics ineligible for deletion: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Ready to serve as the new controller with epoch 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions undergoing preferred replica election: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions that completed preferred replica election: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resuming preferred replica election for partitions: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting preferred replica leader election for partitions 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to localhost:37683 (id: 1 rack: null) for sending state change requests
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting the controller scheduler
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] started
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Topic creation {"version":1,"partitions":{"0":[1]}}
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topics: [Set(schema-changes-topic)], deleted topics: [Set()], new partition replica assignment [Map(schema-changes-topic-0 -> Vector(1))]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topic creation callback for schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New partition creation callback for schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=schema-changes-topic,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=schema-changes-topic,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading producer state from offset 0 for partition schema-changes-topic-0 with message format version 2
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Completed load of log schema-changes-topic-0 with 1 log segments, log start offset 0 and log end offset 0 in 787 ms
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Created log for partition [schema-changes-topic,0] in /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition schema-changes-topic-0 broker=1] No checkpointed highwatermark is found for partition schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Replica loaded for partition schema-changes-topic-0 with initial high watermark 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition schema-changes-topic-0 broker=1] schema-changes-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: schema-changes-topic-0. Cache now contains 0 entries.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Topic creation {"version":1,"partitions":{"0":[1]}}
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaApi-1] Auto creation of topic __consumer_offsets with 1 partitions and replication factor 1 is successful
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-0 -> Vector(1))]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topic creation callback for __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New partition creation callback for __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading producer state from offset 0 for partition __consumer_offsets-0 with message format version 2
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Completed load of log __consumer_offsets-0 with 1 log segments, log start offset 0 and log end offset 0 in 776 ms
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Created log for partition [__consumer_offsets,0] in /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 0 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 1 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 1 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 2 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 2 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 3 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 3
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 3 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 4 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 4 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 5 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 5
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 5 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 6 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 6 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 7 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 7
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 7 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 8 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 8 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 9 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 9
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 9 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 10 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] Starting controlled shutdown
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Shutting down broker 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] Controlled shutdown succeeded
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Kafka Request Handler on Broker 1], shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Kafka Request Handler on Broker 1], shut down completely
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaApi-1] Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction State Manager 1]: Shutdown complete
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaManager broker=1] Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaManager broker=1] Shut down completely
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutting down the log cleaner.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Stopped partition state machine
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Stopped replica state machine
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resigned
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] shut down completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/__consumer_offsets-0/00000000000000000000.index
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/__consumer_offsets-0/00000000000000000000.timeindex
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/schema-changes-topic-0/00000000000000000000.index
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/schema-changes-topic-0/00000000000000000000.timeindex
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Connecting to zookeeper on localhost:38781
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Cluster ID = 6_Z9ajDORPeVRl8ovkrykA
[WARN ] kafka.utils.Logging$class.warn(Logging.scala:87) - No meta.properties file under dir /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/meta.properties
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Log directory '/pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1' not found, creating it.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading logs.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Logs loading complete in 54 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting log cleanup with a period of 300000 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting log flusher with a default period of 9223372036854775807 ms.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Starting the log cleaner
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Awaiting socket connections on localhost:35539.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Started 1 acceptor threads
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Starting up.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Creating /controller (is it secure? false)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Startup complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Result of znode creation is: OK
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] 1 successfully elected as the controller
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting become controller state transition
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Starting up.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Startup complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Incremented epoch to 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Creating /brokers/ids/1 (is it secure? false)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Result of znode creation is: OK
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Registered broker 1 at path /brokers/ids/1 with addresses: EndPoint(localhost,35539,ListenerName(PLAINTEXT),PLAINTEXT)
[WARN ] kafka.utils.Logging$class.warn(Logging.scala:87) - No meta.properties file under dir /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/meta.properties
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions being reassigned: Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions already reassigned: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resuming reassignment of partitions: Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Currently active brokers in the cluster: Set(1)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Currently shutting brokers in the cluster: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Current list of topics in the cluster: Set()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] List of topics to be deleted: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] List of topics ineligible for deletion: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Ready to serve as the new controller with epoch 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions undergoing preferred replica election: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Partitions that completed preferred replica election: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resuming preferred replica election for partitions: 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting preferred replica leader election for partitions 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions 
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Starting
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Controller 1 connected to localhost:35539 (id: 1 rack: null) for sending state change requests
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Starting the controller scheduler
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] started
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Topic creation {"version":1,"partitions":{"0":[1]}}
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topics: [Set(schema-changes-topic)], deleted topics: [Set()], new partition replica assignment [Map(schema-changes-topic-0 -> Vector(1))]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topic creation callback for schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New partition creation callback for schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=schema-changes-topic,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=schema-changes-topic,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading producer state from offset 0 for partition schema-changes-topic-0 with message format version 2
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Completed load of log schema-changes-topic-0 with 1 log segments, log start offset 0 and log end offset 0 in 27 ms
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Created log for partition [schema-changes-topic,0] in /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition schema-changes-topic-0 broker=1] No checkpointed highwatermark is found for partition schema-changes-topic-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Replica loaded for partition schema-changes-topic-0 with initial high watermark 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition schema-changes-topic-0 broker=1] schema-changes-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: schema-changes-topic-0. Cache now contains 0 entries.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Topic creation {"version":1,"partitions":{"0":[1]}}
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaApi-1] Auto creation of topic __consumer_offsets with 1 partitions and replication factor 1 is successful
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-0 -> Vector(1))]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New topic creation callback for __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] New partition creation callback for __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to NewPartition for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=0,Replica=1]
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Loading producer state from offset 0 for partition __consumer_offsets-0 with message format version 2
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Completed load of log __consumer_offsets-0 with 1 log segments, log start offset 0 and log end offset 0 in 27 ms
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Created log for partition [__consumer_offsets,0] in /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1 with properties {compression.type -> producer, message.format.version -> 1.0-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 0 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 1 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset-1} for Partition: __consumer_offsets-0. Cache now contains 0 entries.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 1 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 2 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 2 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 3 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 3
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 3 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 4 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 4 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Stabilized group my-db-history generation 5 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Assignment received from leader for group my-db-history for generation 5
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Preparing to rebalance group my-db-history with old generation 5 (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Group my-db-history with generation 6 is now empty (__consumer_offsets-0)
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] Starting controlled shutdown
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Shutting down broker 1
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] Controlled shutdown succeeded
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [SocketServer brokerId=1] Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Kafka Request Handler on Broker 1], shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Kafka Request Handler on Broker 1], shut down completely
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Fetch]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Produce]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ThrottledRequestReaper-Request]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaApi-1] Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-topic]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction State Manager 1]: Shutdown complete
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Transaction Marker Channel Manager 1]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [TransactionCoordinator id=1] Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Heartbeat]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Rebalance]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [GroupCoordinator 1]: Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaManager broker=1] Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [LogDirFailureHandler]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaFetcherManager on broker 1] shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Fetch]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-Produce]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaManager broker=1] Shut down completely
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutting down.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutting down the log cleaner.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [kafka-log-cleaner-thread-0]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Shutdown complete.
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [controller-event-thread]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [PartitionStateMachine controllerId=1] Stopped partition state machine
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [ReplicaStateMachine controllerId=1] Stopped replica state machine
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Shutting down
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Stopped
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller-1-to-broker-1-send-thread]: Shutdown completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [Controller id=1] Resigned
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - [KafkaServer id=1] shut down completed
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/__consumer_offsets-0/00000000000000000000.index
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/__consumer_offsets-0/00000000000000000000.timeindex
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/schema-changes-topic-0/00000000000000000000.index
[INFO ] kafka.utils.Logging$class.info(Logging.scala:72) - Deleting index /pfs/nobackup/home/d/dginelli/development/target/data/history_cluster/kafka/broker1/schema-changes-topic-0/00000000000000000000.timeindex
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.calculateSuspicious(AstorCoreEngine.java:925) - Setting up the max to 502960 milliseconds (502 sec)
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.initPopulation(AstorCoreEngine.java:720) - 
---- Creating spoon model
[INFO ] fr.inria.astor.core.manipulation.MutationSupporter.buildSpoonModel(MutationSupporter.java:236) - Creating model,  Code location from working folder: /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/debezium-core/src/main/java
[INFO ] fr.inria.astor.core.manipulation.MutationSupporter.buildModel(MutationSupporter.java:67) - building model: /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/debezium-core/src/main/java, compliance level: 8
[INFO ] fr.inria.astor.core.manipulation.MutationSupporter.buildModel(MutationSupporter.java:81) - Classpath (Dependencies) for building SpoonModel: [/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/connect-api/1.0.0/connect-api-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/kafka-clients/1.0.0/kafka-clients-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/lz4/lz4-java/1.4/lz4-java-1.4.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/connect-transforms/1.0.0/connect-transforms-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/fasterxml/jackson/core/jackson-core/2.9.1/jackson-core-2.9.1.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/junit/junit/4.12/junit-4.12.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/easytesting/fest-assert/1.4/fest-assert-1.4.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/easytesting/fest-util/1.1.6/fest-util-1.1.6.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/kafka_2.11/1.0.0/kafka_2.11-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.1/jackson-databind-2.9.1.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/scala-lang/scala-library/2.11.11/scala-library-2.11.11.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/curator/curator-test/2.11.0/curator-test-2.11.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/commons/commons-math/2.2/commons-math-2.2.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/jline/jline/0.9.94/jline-0.9.94.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/connect-json/1.0.0/connect-json-1.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/kafka-connect-avro-converter/4.0.0/kafka-connect-avro-converter-4.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/kafka-avro-serializer/4.0.0/kafka-avro-serializer-4.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/avro/avro/1.8.2/avro-1.8.2.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/thoughtworks/paranamer/paranamer/2.7/paranamer-2.7.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/tukaani/xz/1.5/xz-1.5.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/kafka-schema-registry-client/4.0.0/kafka-schema-registry-client-4.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/common-config/4.0.0/common-config-4.0.0.jar, /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/common-utils/4.0.0/common-utils-4.0.0.jar]
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.initModel(AstorCoreEngine.java:790) - Number of CtTypes created: 136
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.initPopulation(AstorCoreEngine.java:724) - 
---- Initial suspicious size: 80
[INFO ] fr.inria.astor.core.solutionsearch.population.ProgramVariantFactory.createProgramInstance(ProgramVariantFactory.java:134) - Total suspicious from FL: 80,  83
[INFO ] fr.inria.astor.core.solutionsearch.population.ProgramVariantFactory.createProgramInstance(ProgramVariantFactory.java:143) - Total ModPoint created: 83
[INFO ] fr.inria.astor.core.solutionsearch.population.ProgramVariantFactory.createInitialPopulation(ProgramVariantFactory.java:82) - Creating program variant #1, [Variant id: 1, #gens: 83, #ops: 0, parent:-]
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.setFitnessOfPopulation(AstorCoreEngine.java:765) - The original fitness is : 1.0
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:66) - ----------------------------
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:67) - ---Configuration properties:---Execution values
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:lastJUnitVersion= ./examples/libs/junit-4.11.jar
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:alternativecompliancelevel= 8
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:ignoredTestCases= 
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:workingDirectory= /proj/nobackup/snic2020-10-10/dginelli/astor
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:manipulatesuper= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:validation= process
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:jvm4testexecution= /cvmfs/ebsw.hpc2n.umu.se/amd64_ubuntu1604_common/software/Core/Java/1.8.0_202/bin
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:operatorspace= suppression
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:disablelog= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:binjavafolder= /target/classes
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:synthesis_depth= 3
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:gzoltartestpackagetoexclude= junit.framework
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:skipfitnessinitialpopulation= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:evosuiteresultfolder= evosuite
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:flthreshold= 0.1
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:regressionforfaultlocalization= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:collectonlyusedmethod= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:preservelinenumbers= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:tmax2= 502960
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:tmax1= 10000
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:probagenmutation= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:nomodificationconvergence= 100
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:diff_type= relative
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:targetelementprocessor= statements
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:srctestfolder= src/test/java
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:forceExecuteRegression= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:clusteringfilename= clustering.csv
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:logtestexecution= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:evo_buggy_class= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:numberExecutions= 1
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:maxnumbersolutions= 3
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:evo_affected_by_op= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:population= 1
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:considerzerovaluesusp= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:maxCombinationVariableLimit= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:loglevel= INFO
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:savesolution= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:javacompliancelevel= 8
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:uniqueoptogen= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:gzoltarpackagetonotinstrument= junit.framework
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:projectIdentifier= AstorJKali-repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:modificationpointnavigation= weight
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:stopfirst= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:multipointmodification= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:elementsToMutate= 10
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:jsonoutputname= astor_output
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:evoDSE= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:bintestfolder= /target/test-classes
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:testbystep= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:version-location= ./math-version/
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:reintroduce= PARENTS:ORIGINAL
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:executorjar= ./lib/jtestex7.jar
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:maxGeneration= 200
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:max_synthesis_step= 10000
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:projectinfocommand= com.github.tdurieux:project-config-maven-plugin:info
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:maxVarCombination= 1000
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:maxtime= 100
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:evosuitejar= ./lib/evosuite-master-1.0.4-SNAPSHOT.jar
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:jvmversion= 1.8.0_202
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:commandTrunk= 50000
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:faultlocalization= CoCoSpoon
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:resetmodel= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:maxsuspcandidates= 1000
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:mode= jkali
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:learningdir= 
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:jvm4evosuitetestexecution= /cvmfs/ebsw.hpc2n.umu.se/amd64_ubuntu1604_common/software/Core/Java/1.8.0_202/bin
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:filterfaultlocalization= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:mutationrate= 1 
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:pathToMVNRepository= 
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:resourcesfolder= /src/main/resources:/src/test/resources:
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:runjava7code= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:timezone= Europe/Paris
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:evoRunOnBuggyClass= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:compiler= fr.inria.astor.core.manipulation.bytecode.compiler.SpoonClassCompiler
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:limitbysuspicious= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:logsattemps= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:dependenciespath= /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/connect-api/1.0.0/connect-api-1.0.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/kafka-clients/1.0.0/kafka-clients-1.0.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/lz4/lz4-java/1.4/lz4-java-1.4.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/connect-transforms/1.0.0/connect-transforms-1.0.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/fasterxml/jackson/core/jackson-core/2.9.1/jackson-core-2.9.1.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/junit/junit/4.12/junit-4.12.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/easytesting/fest-assert/1.4/fest-assert-1.4.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/easytesting/fest-util/1.1.6/fest-util-1.1.6.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/kafka_2.11/1.0.0/kafka_2.11-1.0.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/fasterxml/jackson/core/jackson-databind/2.9.1/jackson-databind-2.9.1.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/scala-lang/scala-library/2.11.11/scala-library-2.11.11.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/curator/curator-test/2.11.0/curator-test-2.11.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/jline/jline/0.9.94/jline-0.9.94.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/kafka/connect-json/1.0.0/connect-json-1.0.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/kafka-connect-avro-converter/4.0.0/kafka-connect-avro-converter-4.0.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/kafka-avro-serializer/4.0.0/kafka-avro-serializer-4.0.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/com/thoughtworks/paranamer/paranamer/2.7/paranamer-2.7.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/org/tukaani/xz/1.5/xz-1.5.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/kafka-schema-registry-client/4.0.0/kafka-schema-registry-client-4.0.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/common-config/4.0.0/common-config-4.0.0.jar:/scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/.m2/io/confluent/common-utils/4.0.0/common-utils-4.0.0.jar
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:logpatternlayout= [%-5p] %l - %m%n
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:packageToInstrument= 
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:skipfaultlocalization= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:scope= package
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:transformingredient= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:fitnessfunction= fr.inria.astor.core.solutionsearch.population.TestCaseFitnessFunction
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:maxnumvariablesperingredient= 10
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:logfilepath= /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/repairnator.astor.jkali.log
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:parsesourcefromoriginal= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:pvariantfoldername= variant-
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:savespoonmodelondisk= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:srcjavafolder= src/main/java/
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:populationcontroller= fr.inria.astor.core.solutionsearch.population.TestCaseBasedFitnessPopulationController
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:ignoreflakyinfl= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:cleantemplates= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:applyCrossover= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:maxmodificationpoints= 1000
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:duplicateingredientsinspace= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:metid= 0
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:continuewhenmodelfail= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:saveall= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:seed= 1
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:savecompletepatched= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:resetoperations= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:processoutputinfile= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:location= /scratch/dginelli/workspace/repairnator-repairnator-experiments-debezium-debezium-314664721-20171211-101244_bugonly-firstCommit/debezium-core
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:probabilistictransformation= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:overridemaxtime= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:outputjsonresult= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:allpoints= false
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:bugId= 280
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:evosuitetimeout= 120
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:maxtimefactor= 10
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:nrPlaceholders= 1
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:69) - p:forcesubprocesskilling= true
[INFO ] fr.inria.astor.core.setup.ConfigurationProperties.print(ConfigurationProperties.java:71) - ----------------------------
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 879, pointed element: CtContinueImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtContinueImpl) `continue ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 897, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `input.next() ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 894, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (!input.hasNext()) { 	throw new io.debezium.text.ParsingException(input.position(input.index()), [...] ` -topatch--> `if (true) { 	throw new io.debezium.text.ParsingException(input.position(input.index()), "Unterminate[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 894, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (!input.hasNext()) { 	throw new io.debezium.text.ParsingException(input.position(input.index()), [...] ` -topatch--> `if (false) { 	throw new io.debezium.text.ParsingException(input.position(input.index()), "Unterminat[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 894, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (!input.hasNext()) { 	throw new io.debezium.text.ParsingException(input.position(input.index()), [...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 876, pointed element: CtWhileImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtWhileImpl) `while (stream.hasNext()) { 	final java.lang.String part = stream.consume(); 	if (part.length() == 0)[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 878, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (part.length() == 0) { 	continue; } ` -topatch--> `if (true) { 	continue; }` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 878, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (part.length() == 0) { 	continue; } ` -topatch--> `if (false) { 	continue; }` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 878, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (part.length() == 0) { 	continue; } ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 872, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `stream.start() ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 900, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `tokenStart = input.index() + 1 ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 899, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `tokens.addToken(input.position(tokenStart), tokenStart, input.index()) ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 903, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `tokens.addToken(input.position(tokenStart), tokenStart, input.index() + 1) ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 881, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `parts.add(part.replace("\\,", ",")) ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 57, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `matches.add(obj) ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 57, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (obj != null) 	matches.add(obj); ` -topatch--> `if (true) { 	matches.add(obj);}` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 57, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (obj != null) 	matches.add(obj); ` -topatch--> `if (false) { 	matches.add(obj);}` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 57, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (obj != null) 	matches.add(obj); ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 55, pointed element: CtForEachImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtForEachImpl) `for (java.lang.String item : splitter.apply(input)) { 	T obj = factory.apply(item); 	if (obj != null[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 898, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (c == ',') { 	tokens.addToken(input.position(tokenStart), tokenStart, input.index()); 	tokenStart[...] ` -topatch--> `if (true) { 	tokens.addToken(input.position(tokenStart), tokenStart, input.index()); 	tokenStart = i[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 898, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (c == ',') { 	tokens.addToken(input.position(tokenStart), tokenStart, input.index()); 	tokenStart[...] ` -topatch--> `if (false) { 	tokens.addToken(input.position(tokenStart), tokenStart, input.index()); 	tokenStart = [...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 898, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (c == ',') { 	tokens.addToken(input.position(tokenStart), tokenStart, input.index()); 	tokenStart[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 890, pointed element: CtWhileImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtWhileImpl) `while (input.hasNext()) { 	char c = input.next();  	if (c == '\\') { 		if (!input.hasNext()) { 			th[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 893, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (c == '\\') { 	if (!input.hasNext()) { 		throw new io.debezium.text.ParsingException(input.positi[...] ` -topatch--> `if (true) { 	if (!input.hasNext()) { 		throw new io.debezium.text.ParsingException(input.position(in[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 893, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (c == '\\') { 	if (!input.hasNext()) { 		throw new io.debezium.text.ParsingException(input.positi[...] ` -topatch--> `if (false) { 	if (!input.hasNext()) { 		throw new io.debezium.text.ParsingException(input.position(i[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 893, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (c == '\\') { 	if (!input.hasNext()) { 		throw new io.debezium.text.ParsingException(input.positi[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 53, pointed element: CtReturnImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtReturnImpl) `return java.util.Collections.emptySet() ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 53, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (input == null) 	return java.util.Collections.emptySet(); ` -topatch--> `if (true) { 	return java.util.Collections.emptySet();}` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 53, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (input == null) 	return java.util.Collections.emptySet(); ` -topatch--> `if (false) { 	return java.util.Collections.emptySet();}` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.util.Strings line: 53, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (input == null) 	return java.util.Collections.emptySet(); ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2124, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `addToken(position, startIndex, endIndex, 0) ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2353, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `tokens.add(new io.debezium.text.TokenStream.CaseSensitiveToken(startIndex, endIndex, type, position)[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 642, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `moveToNextToken() ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.validation.junit.LaucherJUnitProcess.killProcess(LaucherJUnitProcess.java:179) - The Process that runs JUnit test cases did not terminate within waitTime of 502 seconds
[INFO ] fr.inria.astor.core.validation.junit.LaucherJUnitProcess.killProcess(LaucherJUnitProcess.java:181) - Killed the Process that runs JUnit test cases 109797
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 639, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `throwNoMoreContent() ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 639, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (completed) 	throwNoMoreContent(); ` -topatch--> `if (true) { 	throwNoMoreContent();}` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 639, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (completed) 	throwNoMoreContent(); ` -topatch--> `if (false) { 	throwNoMoreContent();}` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 639, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (completed) 	throwNoMoreContent(); ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1802, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `currentToken = null ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1801, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `completed = true ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1772, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (tokenIterator == null) { 	throw new java.lang.IllegalStateException("start() method must be call[...] ` -topatch--> `if (true) { 	throw new java.lang.IllegalStateException("start() method must be called before hasNext[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1772, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (tokenIterator == null) { 	throw new java.lang.IllegalStateException("start() method must be call[...] ` -topatch--> `if (false) { 	throw new java.lang.IllegalStateException("start() method must be called before hasNex[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1772, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (tokenIterator == null) { 	throw new java.lang.IllegalStateException("start() method must be call[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1822, pointed element: CtAssertImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssertImpl) `assert currentToken != null ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1816, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (currentToken == null) { 	if (completed) { 		throw new java.util.NoSuchElementException("No more [...] ` -topatch--> `if (true) { 	if (this.completed) { 		throw new java.util.NoSuchElementException("No more content"); [...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1816, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (currentToken == null) { 	if (completed) { 		throw new java.util.NoSuchElementException("No more [...] ` -topatch--> `if (false) { 	if (this.completed) { 		throw new java.util.NoSuchElementException("No more content");[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1816, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (currentToken == null) { 	if (completed) { 		throw new java.util.NoSuchElementException("No more [...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1800, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (!tokenIterator.hasNext()) { 	completed = true; 	currentToken = null; } else { 	currentToken = to[...] ` -topatch--> `if (true) { 	this.completed = true; 	this.currentToken = null; } else { 	this.currentToken = this.to[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1800, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (!tokenIterator.hasNext()) { 	completed = true; 	currentToken = null; } else { 	currentToken = to[...] ` -topatch--> `if (false) { 	this.completed = true; 	this.currentToken = null; } else { 	this.currentToken = this.t[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1800, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (!tokenIterator.hasNext()) { 	completed = true; 	currentToken = null; } else { 	currentToken = to[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 1804, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `currentToken = tokenIterator.next() ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 445, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.tokens = initializeTokens(tokenFactory.getTokens()) ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 444, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `tokenizer.tokenize(characterStream, tokenFactory) ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 450, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `moveToNextToken() ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 449, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `tokenIterator = this.tokens.listIterator() ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2254, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.position = position ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2253, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.type = type ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2252, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.endIndex = endIndex ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2251, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.startIndex = startIndex ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2380, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.maxIndex = content.length - 1 ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2379, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.content = content ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2405, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (lastIndex >= maxIndex) { 	throw new java.util.NoSuchElementException(); } ` -topatch--> `if (true) { 	throw new java.util.NoSuchElementException(); }` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2405, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (lastIndex >= maxIndex) { 	throw new java.util.NoSuchElementException(); } ` -topatch--> `if (false) { 	throw new java.util.NoSuchElementException(); }` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2405, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (lastIndex >= maxIndex) { 	throw new java.util.NoSuchElementException(); } ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2410, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (result == '\r') { 	nextCharMayBeLineFeed = true; 	++lineNumber; 	columnNumber = 0; } else 	if (r[...] ` -topatch--> `if (true) { 	this.nextCharMayBeLineFeed = true; 	++this.lineNumber; 	this.columnNumber = 0; } else {[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2410, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (result == '\r') { 	nextCharMayBeLineFeed = true; 	++lineNumber; 	columnNumber = 0; } else 	if (r[...] ` -topatch--> `if (false) { 	this.nextCharMayBeLineFeed = true; 	++this.lineNumber; 	this.columnNumber = 0; } else [...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2410, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (result == '\r') { 	nextCharMayBeLineFeed = true; 	++lineNumber; 	columnNumber = 0; } else 	if (r[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2414, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (result == '\n') { 	if (!nextCharMayBeLineFeed) 		++lineNumber; 	columnNumber = 0; } else 	if (ne[...] ` -topatch--> `if (true) { 	if (!this.nextCharMayBeLineFeed) { 		++this.lineNumber;} 	this.columnNumber = 0; } else[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2414, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (result == '\n') { 	if (!nextCharMayBeLineFeed) 		++lineNumber; 	columnNumber = 0; } else 	if (ne[...] ` -topatch--> `if (false) { 	if (!this.nextCharMayBeLineFeed) { 		++this.lineNumber;} 	this.columnNumber = 0; } els[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2414, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (result == '\n') { 	if (!nextCharMayBeLineFeed) 		++lineNumber; 	columnNumber = 0; } else 	if (ne[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2417, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (nextCharMayBeLineFeed) { 	nextCharMayBeLineFeed = false; } ` -topatch--> `if (true) { 	this.nextCharMayBeLineFeed = false; }` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2417, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (nextCharMayBeLineFeed) { 	nextCharMayBeLineFeed = false; } ` -topatch--> `if (false) { 	this.nextCharMayBeLineFeed = false; }` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 2417, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (nextCharMayBeLineFeed) { 	nextCharMayBeLineFeed = false; } ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 441, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (tokens == null) { 	io.debezium.text.TokenStream.TokenFactory tokenFactory = (caseSensitive) ? ne[...] ` -topatch--> `if (true) { 	io.debezium.text.TokenStream.TokenFactory tokenFactory = (this.caseSensitive) ? new io.[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 441, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
ReplaceIfBooleanOp:(spoon.support.reflect.code.CtIfImpl) `if (tokens == null) { 	io.debezium.text.TokenStream.TokenFactory tokenFactory = (caseSensitive) ? ne[...] ` -topatch--> `if (false) { 	io.debezium.text.TokenStream.TokenFactory tokenFactory = (this.caseSensitive) ? new io[...]` (spoon.support.reflect.code.CtIfImpl) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 441, pointed element: CtIfImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtIfImpl) `if (tokens == null) { 	io.debezium.text.TokenStream.TokenFactory tokenFactory = (caseSensitive) ? ne[...] ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 426, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `java.util.Objects.requireNonNull(tokenizer, "tokenizer") ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 425, pointed element: CtInvocationImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtInvocationImpl) `java.util.Objects.requireNonNull(content, "content") ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 430, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.tokenizer = tokenizer ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 429, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.caseSensitive = caseSensitive ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 428, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.inputContent = content.toCharArray() ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.TokenStream line: 427, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.inputString = content ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.Position line: 36, pointed element: CtAssertImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssertImpl) `assert this.column >= 0 ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.Position line: 35, pointed element: CtAssertImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssertImpl) `assert this.line > 0 ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.Position line: 38, pointed element: CtAssertImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssertImpl) `assert this.indexInContent < 0 ? (this.line == 1) && (this.column == 0) : true ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.Position line: 32, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.column = column ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.Position line: 31, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.line = line ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.Position line: 34, pointed element: CtAssertImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssertImpl) `assert this.indexInContent >= (-1) ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:59) - mod_point MP=io.debezium.text.Position line: 30, pointed element: CtAssignmentImpl
[INFO ] fr.inria.astor.core.solutionsearch.ExhaustiveSearchEngine.startEvolution(ExhaustiveSearchEngine.java:60) - -->op: OP_INSTANCE:
RemoveOp:(spoon.support.reflect.code.CtAssignmentImpl) `this.indexInContent = (indexInContent < 0) ? -1 : indexInContent ` -topatch--> `-` (null) 
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.atEnd(AstorCoreEngine.java:171) - Time Repair Loop (s): 1679.868
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.atEnd(AstorCoreEngine.java:173) - generationsexecuted: 1
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.printFinalStatus(AstorCoreEngine.java:255) - 
----SUMMARY_EXECUTION---
[INFO ] fr.inria.astor.core.solutionsearch.AstorCoreEngine.printFinalStatus(AstorCoreEngine.java:265) - End Repair Search: NOT Found solution
[INFO ] fr.inria.main.evolution.AstorMain.run(AstorMain.java:190) - Time Total(s): 1755.606
